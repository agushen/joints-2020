{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:\\\\Users\\\\Agus Hendra Nasution\\\\Documents\\\\Competition 2020\\\\Joints\\\\train_data.csv')\n",
    "test = pd.read_csv('C:\\\\Users\\\\Agus Hendra Nasution\\\\Documents\\\\Competition 2020\\\\Joints\\\\test_data.csv')\n",
    "submission = pd.read_csv('C:\\\\Users\\\\Agus Hendra Nasution\\\\Documents\\\\Competition 2020\\\\Joints\\\\sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word-1</th>\n",
       "      <th>word-2</th>\n",
       "      <th>word-3</th>\n",
       "      <th>word-4</th>\n",
       "      <th>word-5</th>\n",
       "      <th>word-6</th>\n",
       "      <th>word-7</th>\n",
       "      <th>word-8</th>\n",
       "      <th>word-9</th>\n",
       "      <th>...</th>\n",
       "      <th>word-32</th>\n",
       "      <th>word-33</th>\n",
       "      <th>word-34</th>\n",
       "      <th>word-35</th>\n",
       "      <th>word-36</th>\n",
       "      <th>word-37</th>\n",
       "      <th>word-38</th>\n",
       "      <th>word-39</th>\n",
       "      <th>word-40</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>263</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id word-1  word-2  word-3  word-4 word-5  word-6  word-7 word-8 word-9  \\\n",
       "0   1      5     0.0     0.0     0.0      0     0.0     0.0      1      0   \n",
       "1   2    117     1.0     4.0     3.0    NaN     5.0     2.0      9     19   \n",
       "2   3     30     1.0     1.0     5.0      8     3.0     2.0      2      2   \n",
       "3   4      3     0.0     0.0     0.0      0     0.0     0.0      0      1   \n",
       "4   5    263     6.0     8.0     8.0    NaN    26.0     1.0     21     35   \n",
       "\n",
       "   ... word-32 word-33  word-34 word-35 word-36  word-37  word-38 word-39  \\\n",
       "0  ...     0.0       0      0.0       0     0.0      0.0        0       0   \n",
       "1  ...     3.0      13      9.0      15     3.0      NaN       13       3   \n",
       "2  ...     1.0       5      1.0       1     1.0      0.0        0       0   \n",
       "3  ...     0.0     NaN      0.0       0     0.0      0.0      NaN       0   \n",
       "4  ...    10.0     NaN      5.0      49    26.0     24.0       23       4   \n",
       "\n",
       "  word-40 Result  \n",
       "0       0      0  \n",
       "1       1      0  \n",
       "2       0      0  \n",
       "3       0      0  \n",
       "4      24      1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keanehan nilai dari setiap kolom\n",
    "kolom_huruf = [('word-1','a','588184'), ('word-5','4+F2185','11h','a'), ('word-8','a','`16'),('word-9','`','`29'), ('word-10','`10'), ('word-11','\\\\'),('word-13','a','`27'),\n",
    "              ('word-14','`3'),('word-17','a','`4'),('word-18','\\\\','a'),('word-19','`155','`363','`361', '`51','`764','`84','994821','536457','`61'),\n",
    "              ('word-22','31415669','`21','`11'),('word-24','`2'), ('word-27','`2','['), ('word-28','a'), ('word-30','a'),('word-33','`10','`18','a'),('word-35','`3'),\n",
    "              ('word-38','412334','`10'),('word-39','`1'),('word-40','a')]\n",
    "\n",
    "'''\n",
    "Dapat diambil kesimpulan jika dikelompokkan, nilai unique dari setiap kesalahan input adalah :\n",
    "1. 'a' --> dibikin nan atau nilai tertentu ?\n",
    "2. '`' --> Paling banyak, nanti di hilangkan maka itu nilai yang asli\n",
    "3. '\\\\' --> sedikit, fix NaN\n",
    "4.  '[' --> sedikit, fix NaN\n",
    "5. 31415669 --> kasus angka sebanyak ini, dijadikan nan atau nilai tertentu ?\n",
    "6. 4+F2185 --> Fix NaN\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Membuat dictionary, dimana keynya berupa nomor kolom, dan valuenya adalah nilai kolom_huruf\n",
    "# Ini digunakan untuk looping\n",
    "kolom_huruf = {1:kolom_huruf[0],5:kolom_huruf[1],8:kolom_huruf[2],9:kolom_huruf[3],10:kolom_huruf[4],11:kolom_huruf[5],13:kolom_huruf[6],14:kolom_huruf[7],17:kolom_huruf[8],\n",
    "              18:kolom_huruf[9],19:kolom_huruf[10], 22:kolom_huruf[11], 24:kolom_huruf[12], 27:kolom_huruf[13], 28:kolom_huruf[14], 30:kolom_huruf[15], 33:kolom_huruf[16],\n",
    "              35:kolom_huruf[17],38:kolom_huruf[18],39:kolom_huruf[19],40:kolom_huruf[20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat fungsi mengganti huruf atau benerin nilai yang inputnya salah\n",
    "def ganti_huruf(kolom,huruf):\n",
    "    \n",
    "    nomor_row = 0\n",
    "    for i in range(train.shape[0]):\n",
    "        if train.iloc[i,kolom] == huruf:\n",
    "            # Menyimpan nomor row untuk mengetahui row keberapa dimana a itu berada\n",
    "            #print('nomor_kolom :',i)\n",
    "            nomor_row = i \n",
    " \n",
    "    # Test apakah row tersebut bener atau gak\n",
    "   # print('testing apakah bener:',train.iloc[nomor_row,kolom])\n",
    "    \n",
    "    # Ganti huruf tersebut menjadi nan atau hilangkan tanda '`'\n",
    "    if kolom == 9:\n",
    "        if '`' in huruf:\n",
    "            train.iloc[nomor_row,kolom] = np.nan\n",
    "            \n",
    "    elif 'a' in huruf:\n",
    "        train.iloc[nomor_row,kolom] = 0\n",
    "        \n",
    "    elif  '`' in huruf:\n",
    "        train.iloc[nomor_row,kolom] = huruf[1:] \n",
    "        \n",
    "    elif 'h' in huruf:\n",
    "        train.iloc[nomor_row,kolom] = huruf[:-1] # untuk nangkep word-5 --> '11h'\n",
    "    \n",
    "    else:\n",
    "        #print(kolom,huruf)\n",
    "        train.iloc[nomor_row,kolom] = np.nan\n",
    "   # print('Berhasil !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping fungsi ganti_huruf untuk setiap kolom_huruf !\n",
    "for key,value in kolom_huruf.items():\n",
    "    \n",
    "    # Dibuat error excepition karena nanti akan terjadi IndexError !\n",
    "    try :\n",
    "        for j in range(len(value)):\n",
    "            \n",
    "            # key --> kolom, value --> huruf\n",
    "            ganti_huruf(key,value[j+1])\n",
    "            \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolom 8 dan 13, entah kenapa tidak berhasil untuk mengganti huruf a diatas ! jadi dilakukan secara terpisah dari looping\n",
    "ganti_huruf(8,'a')\n",
    "ganti_huruf(13,'a')\n",
    "# Missing Values\n",
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3620 entries, 0 to 3619\n",
      "Data columns (total 42 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   id       3620 non-null   int64\n",
      " 1   word-1   3620 non-null   int32\n",
      " 2   word-2   3620 non-null   int32\n",
      " 3   word-3   3620 non-null   int32\n",
      " 4   word-4   3620 non-null   int32\n",
      " 5   word-5   3620 non-null   int32\n",
      " 6   word-6   3620 non-null   int32\n",
      " 7   word-7   3620 non-null   int32\n",
      " 8   word-8   3620 non-null   int32\n",
      " 9   word-9   3620 non-null   int32\n",
      " 10  word-10  3620 non-null   int32\n",
      " 11  word-11  3620 non-null   int32\n",
      " 12  word-12  3620 non-null   int32\n",
      " 13  word-13  3620 non-null   int32\n",
      " 14  word-14  3620 non-null   int32\n",
      " 15  word-15  3620 non-null   int32\n",
      " 16  word-16  3620 non-null   int32\n",
      " 17  word-17  3620 non-null   int32\n",
      " 18  word-18  3620 non-null   int32\n",
      " 19  word-19  3620 non-null   int32\n",
      " 20  word-20  3620 non-null   int32\n",
      " 21  word-21  3620 non-null   int32\n",
      " 22  word-22  3620 non-null   int32\n",
      " 23  word-23  3620 non-null   int32\n",
      " 24  word-24  3620 non-null   int32\n",
      " 25  word-25  3620 non-null   int32\n",
      " 26  word-26  3620 non-null   int32\n",
      " 27  word-27  3620 non-null   int32\n",
      " 28  word-28  3620 non-null   int32\n",
      " 29  word-29  3620 non-null   int32\n",
      " 30  word-30  3620 non-null   int32\n",
      " 31  word-31  3620 non-null   int32\n",
      " 32  word-32  3620 non-null   int32\n",
      " 33  word-33  3620 non-null   int32\n",
      " 34  word-34  3620 non-null   int32\n",
      " 35  word-35  3620 non-null   int32\n",
      " 36  word-36  3620 non-null   int32\n",
      " 37  word-37  3620 non-null   int32\n",
      " 38  word-38  3620 non-null   int32\n",
      " 39  word-39  3620 non-null   int32\n",
      " 40  word-40  3620 non-null   int32\n",
      " 41  Result   3620 non-null   int64\n",
      "dtypes: int32(40), int64(2)\n",
      "memory usage: 622.3 KB\n"
     ]
    }
   ],
   "source": [
    "kolom = ['word-1', 'word-2', 'word-3', 'word-4', 'word-5', 'word-6',\n",
    "       'word-7', 'word-8', 'word-9', 'word-10', 'word-11', 'word-12',\n",
    "       'word-13', 'word-14', 'word-15', 'word-16', 'word-17', 'word-18',\n",
    "       'word-19', 'word-20', 'word-21', 'word-22', 'word-23', 'word-24',\n",
    "       'word-25', 'word-26', 'word-27', 'word-28', 'word-29', 'word-30',\n",
    "       'word-31', 'word-32', 'word-33', 'word-34', 'word-35', 'word-36',\n",
    "       'word-37', 'word-38', 'word-39', 'word-40']\n",
    "\n",
    "# Mengganti tipe data object ke float\n",
    "for i in kolom:\n",
    "\n",
    "    train[i] = train[i].astype('int')\n",
    "    \n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambahan data error ! \n",
    "train.loc[32, 'word-4'] = 1 # eror karena -1\n",
    "train.loc[24, 'word-25'] = 9 # error karena -9\n",
    "train.loc[3220, 'word-36'] = 0 # error karena nilainya sangat besar, contoh : 1295321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word-1</th>\n",
       "      <th>word-2</th>\n",
       "      <th>word-3</th>\n",
       "      <th>word-4</th>\n",
       "      <th>word-5</th>\n",
       "      <th>word-6</th>\n",
       "      <th>word-7</th>\n",
       "      <th>word-8</th>\n",
       "      <th>word-9</th>\n",
       "      <th>word-10</th>\n",
       "      <th>...</th>\n",
       "      <th>word-31</th>\n",
       "      <th>word-32</th>\n",
       "      <th>word-33</th>\n",
       "      <th>word-34</th>\n",
       "      <th>word-35</th>\n",
       "      <th>word-36</th>\n",
       "      <th>word-37</th>\n",
       "      <th>word-38</th>\n",
       "      <th>word-39</th>\n",
       "      <th>word-40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word-1  word-2  word-3  word-4  word-5  word-6  word-7  word-8  word-9  \\\n",
       "0     5.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "1   117.0     1.0     4.0     3.0     0.0     5.0     2.0     9.0    19.0   \n",
       "2    30.0     1.0     1.0     5.0     8.0     3.0     2.0     2.0     2.0   \n",
       "3     3.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "4   263.0     6.0     8.0     8.0     0.0    26.0     1.0    21.0    35.0   \n",
       "\n",
       "   word-10  ...  word-31  word-32  word-33  word-34  word-35  word-36  \\\n",
       "0      1.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      6.0  ...      1.0      3.0     13.0      9.0     15.0      3.0   \n",
       "2      1.0  ...      0.0      1.0      5.0      1.0      1.0      1.0   \n",
       "3      0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4     10.0  ...      6.0     10.0      0.0      5.0     49.0     26.0   \n",
       "\n",
       "   word-37  word-38  word-39  word-40  \n",
       "0      0.0      0.0      0.0      0.0  \n",
       "1      0.0     13.0      3.0      1.0  \n",
       "2      0.0      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0      0.0  \n",
       "4     24.0     23.0      4.0     24.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.fillna(0)\n",
    "train_ = train.drop(columns = 'Result')\n",
    "full = pd.concat([train_,test])\n",
    "full = full.drop(columns = 'id')\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word-1</th>\n",
       "      <th>word-2</th>\n",
       "      <th>word-3</th>\n",
       "      <th>word-4</th>\n",
       "      <th>word-5</th>\n",
       "      <th>word-6</th>\n",
       "      <th>word-7</th>\n",
       "      <th>word-8</th>\n",
       "      <th>word-9</th>\n",
       "      <th>word-10</th>\n",
       "      <th>...</th>\n",
       "      <th>word-31</th>\n",
       "      <th>word-32</th>\n",
       "      <th>word-33</th>\n",
       "      <th>word-34</th>\n",
       "      <th>word-35</th>\n",
       "      <th>word-36</th>\n",
       "      <th>word-37</th>\n",
       "      <th>word-38</th>\n",
       "      <th>word-39</th>\n",
       "      <th>word-40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word-1  word-2  word-3  word-4  word-5  word-6  word-7  word-8  word-9  \\\n",
       "0     5.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "1   117.0     1.0     4.0     3.0     0.0     5.0     2.0     9.0    19.0   \n",
       "2    30.0     1.0     1.0     5.0     8.0     3.0     2.0     2.0     2.0   \n",
       "3     3.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "4   263.0     6.0     8.0     8.0     0.0    26.0     1.0    21.0    35.0   \n",
       "\n",
       "   word-10  ...  word-31  word-32  word-33  word-34  word-35  word-36  \\\n",
       "0      1.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      6.0  ...      1.0      3.0     13.0      9.0     15.0      3.0   \n",
       "2      1.0  ...      0.0      1.0      5.0      1.0      1.0      1.0   \n",
       "3      0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4     10.0  ...      6.0     10.0      0.0      5.0     49.0     26.0   \n",
       "\n",
       "   word-37  word-38  word-39  word-40  \n",
       "0      0.0      0.0      0.0      0.0  \n",
       "1      0.0     13.0      3.0      1.0  \n",
       "2      0.0      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0      0.0  \n",
       "4     24.0     23.0      4.0     24.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full1 = full.copy()\n",
    "\n",
    "X_train_full1 = full1.iloc[:3620] \n",
    "X_test_full1 = full1.iloc[3620:] \n",
    "\n",
    "X1 = X_train_full1\n",
    "y1 = train.Result\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word-1</th>\n",
       "      <th>word-2</th>\n",
       "      <th>word-3</th>\n",
       "      <th>word-4</th>\n",
       "      <th>word-5</th>\n",
       "      <th>word-6</th>\n",
       "      <th>word-7</th>\n",
       "      <th>word-8</th>\n",
       "      <th>word-9</th>\n",
       "      <th>word-10</th>\n",
       "      <th>...</th>\n",
       "      <th>word-31</th>\n",
       "      <th>word-32</th>\n",
       "      <th>word-33</th>\n",
       "      <th>word-34</th>\n",
       "      <th>word-35</th>\n",
       "      <th>word-36</th>\n",
       "      <th>word-37</th>\n",
       "      <th>word-38</th>\n",
       "      <th>word-39</th>\n",
       "      <th>word-40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.017203</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01747</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>0.027029</td>\n",
       "      <td>0.013199</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014439</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>0.006978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.019807</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>0.01428</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.013271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word-1    word-2    word-3    word-4    word-5    word-6    word-7  \\\n",
       "0  0.007086  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.004164  0.001564  0.007181  0.004480  0.000000  0.006010  0.003224   \n",
       "2  0.003865  0.005662  0.006498  0.027029  0.013199  0.013053  0.011669   \n",
       "3  0.005846  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.004325  0.004336  0.006635  0.005520  0.000000  0.014439  0.000745   \n",
       "\n",
       "     word-8    word-9   word-10  ...   word-31   word-32   word-33   word-34  \\\n",
       "0  0.024896  0.000000  0.033090  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.005627  0.007818  0.004986  ...  0.002216  0.004531  0.009009  0.017203   \n",
       "2  0.004527  0.002979  0.003008  ...  0.000000  0.005467  0.012543  0.006919   \n",
       "3  0.000000  0.022529  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.006066  0.006654  0.003840  ...  0.006144  0.006978  0.000000  0.004416   \n",
       "\n",
       "    word-35   word-36   word-37  word-38   word-39   word-40  \n",
       "0  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  \n",
       "1  0.008047  0.004946  0.000000  0.01747  0.004012  0.001197  \n",
       "2  0.001942  0.005968  0.000000  0.00000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  \n",
       "4  0.012145  0.019807  0.012068  0.01428  0.002472  0.013271  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full2 = full.copy()\n",
    "\n",
    "from array import array\n",
    "tf = 1/full2.sum(axis=1)[:,None]\n",
    "full2 = full2*tf\n",
    "\n",
    "idf = np.log(full2.shape[0]/ (full2>0).sum())\n",
    "full2 = full2*idf\n",
    "\n",
    "full2 = full2.fillna(0)\n",
    "\n",
    "X_train_full2 = full2.iloc[:3620] \n",
    "X_test_full2 = full2.iloc[3620:] \n",
    "\n",
    "X2 = X_train_full2\n",
    "y2 = train.Result\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word-1</th>\n",
       "      <th>word-2</th>\n",
       "      <th>word-3</th>\n",
       "      <th>word-4</th>\n",
       "      <th>word-5</th>\n",
       "      <th>word-6</th>\n",
       "      <th>word-7</th>\n",
       "      <th>word-8</th>\n",
       "      <th>word-9</th>\n",
       "      <th>word-10</th>\n",
       "      <th>...</th>\n",
       "      <th>word-31binary</th>\n",
       "      <th>word-32binary</th>\n",
       "      <th>word-33binary</th>\n",
       "      <th>word-34binary</th>\n",
       "      <th>word-35binary</th>\n",
       "      <th>word-36binary</th>\n",
       "      <th>word-37binary</th>\n",
       "      <th>word-38binary</th>\n",
       "      <th>word-39binary</th>\n",
       "      <th>word-40binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word-1  word-2  word-3  word-4  word-5  word-6  word-7  word-8  word-9  \\\n",
       "0     5.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "1   117.0     1.0     4.0     3.0     0.0     5.0     2.0     9.0    19.0   \n",
       "2    30.0     1.0     1.0     5.0     8.0     3.0     2.0     2.0     2.0   \n",
       "3     3.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "4   263.0     6.0     8.0     8.0     0.0    26.0     1.0    21.0    35.0   \n",
       "\n",
       "   word-10  ...  word-31binary  word-32binary  word-33binary  word-34binary  \\\n",
       "0      1.0  ...              0              0              0              0   \n",
       "1      6.0  ...              1              1              1              1   \n",
       "2      1.0  ...              0              1              1              1   \n",
       "3      0.0  ...              0              0              0              0   \n",
       "4     10.0  ...              1              1              0              1   \n",
       "\n",
       "   word-35binary  word-36binary  word-37binary  word-38binary  word-39binary  \\\n",
       "0              0              0              0              0              0   \n",
       "1              1              1              0              1              1   \n",
       "2              1              1              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              1              1              1              1              1   \n",
       "\n",
       "   word-40binary  \n",
       "0              0  \n",
       "1              1  \n",
       "2              0  \n",
       "3              0  \n",
       "4              1  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from sklearn.decomposition import PCA\n",
    "full3 = full.copy()\n",
    "\n",
    "binary = list()\n",
    "for i in range(len(full3)):\n",
    "    bi = list()\n",
    "    for j in full3.iloc[i,]:\n",
    "        if j != 0:\n",
    "            bi.append(1)\n",
    "        else: bi.append(0)\n",
    "    binary.append(bi)\n",
    "    \n",
    "ha = pd.DataFrame(binary, columns = full.columns)\n",
    "\n",
    "for i in ha.columns:\n",
    "        full3[i+'binary'] = ha[i]\n",
    "\n",
    "X_train_full3 = full3.iloc[:3620] \n",
    "X_test_full3 = full3.iloc[3620:] \n",
    "\n",
    "X3 = X_train_full3\n",
    "y3 = train.Result\n",
    "\n",
    "X3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "full4 = full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_words = list()\n",
    "for j in range(len(full4)): \n",
    "    std_words.append(full4.iloc[j].std())\n",
    "    \n",
    "std_words = pd.Series(std_words)\n",
    "\n",
    "\n",
    "jumlah_kata = list()\n",
    "for i in range(len(full4)):\n",
    "    jumlah_kata.append(full4.iloc[i,].sum())\n",
    "               \n",
    "Total_Kata = pd.Series(jumlah_kata)\n",
    "\n",
    "unique_words = list()\n",
    "jumlah_unique = 0\n",
    "for j in range(len(full4)):\n",
    "    for key,i in full4.iloc[j].items():\n",
    "        if key != 'Result':\n",
    "            if i == 1:\n",
    "                jumlah_unique += 1\n",
    "    unique_words.append(jumlah_unique)\n",
    "    jumlah_unique = 0\n",
    "    \n",
    "unique_words = pd.Series(unique_words)\n",
    "    \n",
    "absence_words = list()\n",
    "jumlah_absence = 0\n",
    "for j in range(len(full4)):\n",
    "    for key,i in full4.iloc[j].items():\n",
    "        if key != 'Result':\n",
    "            if i == 0:\n",
    "                jumlah_absence += 1\n",
    "    absence_words.append(jumlah_absence)\n",
    "    jumlah_absence = 0\n",
    "absence_words = pd.Series(absence_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from array import array\n",
    "tf = 1/full4.sum(axis=1)[:,None]\n",
    "full4 = full4*tf\n",
    "\n",
    "idf = np.log(full4.shape[0]/ (full4>0).sum())\n",
    "full4 = full4*idf\n",
    "\n",
    "full4 = full4.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "full4['Kata_Unik'] = unique_words\n",
    "full4['Persentase_Unik_vs_TotalKata'] = (pd.Series(unique_words).multiply(100))/pd.Series(Total_Kata)\n",
    "full4['Std_Kata'] = std_words\n",
    "full4['Absen_Kata'] = absence_words\n",
    "full4['Total_Kata'] = Total_Kata\n",
    "full4['multiply_18_34'] = full['word-18'].multiply(full['word-34'])\n",
    "full4['multiply_15_33'] = full['word-15'].multiply(full['word-33'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "full4 = full4.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word-1</th>\n",
       "      <th>word-2</th>\n",
       "      <th>word-3</th>\n",
       "      <th>word-4</th>\n",
       "      <th>word-5</th>\n",
       "      <th>word-6</th>\n",
       "      <th>word-7</th>\n",
       "      <th>word-8</th>\n",
       "      <th>word-9</th>\n",
       "      <th>word-10</th>\n",
       "      <th>...</th>\n",
       "      <th>word-38</th>\n",
       "      <th>word-39</th>\n",
       "      <th>word-40</th>\n",
       "      <th>Kata_Unik</th>\n",
       "      <th>Persentase_Unik_vs_TotalKata</th>\n",
       "      <th>Std_Kata</th>\n",
       "      <th>Absen_Kata</th>\n",
       "      <th>Total_Kata</th>\n",
       "      <th>multiply_18_34</th>\n",
       "      <th>multiply_15_33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>0.846940</td>\n",
       "      <td>33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01747</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>5</td>\n",
       "      <td>1.141553</td>\n",
       "      <td>21.620207</td>\n",
       "      <td>5</td>\n",
       "      <td>438.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>0.027029</td>\n",
       "      <td>0.013199</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>14.876033</td>\n",
       "      <td>5.553874</td>\n",
       "      <td>8</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>0.563869</td>\n",
       "      <td>34</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014439</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01428</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.013271</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105485</td>\n",
       "      <td>42.429549</td>\n",
       "      <td>3</td>\n",
       "      <td>948.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word-1    word-2    word-3    word-4    word-5    word-6    word-7  \\\n",
       "0  0.007086  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.004164  0.001564  0.007181  0.004480  0.000000  0.006010  0.003224   \n",
       "2  0.003865  0.005662  0.006498  0.027029  0.013199  0.013053  0.011669   \n",
       "3  0.005846  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.004325  0.004336  0.006635  0.005520  0.000000  0.014439  0.000745   \n",
       "\n",
       "     word-8    word-9   word-10  ...  word-38   word-39   word-40  Kata_Unik  \\\n",
       "0  0.024896  0.000000  0.033090  ...  0.00000  0.000000  0.000000          6   \n",
       "1  0.005627  0.007818  0.004986  ...  0.01747  0.004012  0.001197          5   \n",
       "2  0.004527  0.002979  0.003008  ...  0.00000  0.000000  0.000000         18   \n",
       "3  0.000000  0.022529  0.000000  ...  0.00000  0.000000  0.000000          5   \n",
       "4  0.006066  0.006654  0.003840  ...  0.01428  0.002472  0.013271          1   \n",
       "\n",
       "   Persentase_Unik_vs_TotalKata   Std_Kata  Absen_Kata  Total_Kata  \\\n",
       "0                     54.545455   0.846940          33        11.0   \n",
       "1                      1.141553  21.620207           5       438.0   \n",
       "2                     14.876033   5.553874           8       121.0   \n",
       "3                     62.500000   0.563869          34         8.0   \n",
       "4                      0.105485  42.429549           3       948.0   \n",
       "\n",
       "   multiply_18_34  multiply_15_33  \n",
       "0             0.0             0.0  \n",
       "1            81.0           195.0  \n",
       "2             1.0            35.0  \n",
       "3             0.0             0.0  \n",
       "4            30.0             0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full4 = full4.iloc[:3620] \n",
    "X_test_full4 = full4.iloc[3620:] \n",
    "\n",
    "X4 = X_train_full4\n",
    "y4 = train.Result\n",
    "X4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "full5 = full.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumlah_kata = list()\n",
    "for i in range(len(full5)):\n",
    "    jumlah_kata.append(full5.iloc[i,].sum())\n",
    "               \n",
    "Total_Kata = pd.Series(jumlah_kata)\n",
    "\n",
    "full5['multiply_18_34'] = full4['word-18'].multiply(full4['word-34'])\n",
    "full5['Total_Kata'] = Total_Kata\n",
    "full5['multiply_15_33'] = full['word-15'].multiply(full['word-33'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word-1</th>\n",
       "      <th>word-2</th>\n",
       "      <th>word-3</th>\n",
       "      <th>word-4</th>\n",
       "      <th>word-5</th>\n",
       "      <th>word-6</th>\n",
       "      <th>word-7</th>\n",
       "      <th>word-8</th>\n",
       "      <th>word-9</th>\n",
       "      <th>word-10</th>\n",
       "      <th>...</th>\n",
       "      <th>word-34</th>\n",
       "      <th>word-35</th>\n",
       "      <th>word-36</th>\n",
       "      <th>word-37</th>\n",
       "      <th>word-38</th>\n",
       "      <th>word-39</th>\n",
       "      <th>word-40</th>\n",
       "      <th>multiply_18_34</th>\n",
       "      <th>Total_Kata</th>\n",
       "      <th>multiply_15_33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>438.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>121.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word-1  word-2  word-3  word-4  word-5  word-6  word-7  word-8  word-9  \\\n",
       "0     5.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "1   117.0     1.0     4.0     3.0     0.0     5.0     2.0     9.0    19.0   \n",
       "2    30.0     1.0     1.0     5.0     8.0     3.0     2.0     2.0     2.0   \n",
       "3     3.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "4   263.0     6.0     8.0     8.0     0.0    26.0     1.0    21.0    35.0   \n",
       "\n",
       "   word-10  ...  word-34  word-35  word-36  word-37  word-38  word-39  \\\n",
       "0      1.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      6.0  ...      9.0     15.0      3.0      0.0     13.0      3.0   \n",
       "2      1.0  ...      1.0      1.0      1.0      0.0      0.0      0.0   \n",
       "3      0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4     10.0  ...      5.0     49.0     26.0     24.0     23.0      4.0   \n",
       "\n",
       "   word-40  multiply_18_34  Total_Kata  multiply_15_33  \n",
       "0      0.0        0.000000        11.0             0.0  \n",
       "1      1.0        0.000280       438.0           195.0  \n",
       "2      0.0        0.000045       121.0            35.0  \n",
       "3      0.0        0.000000         8.0             0.0  \n",
       "4     24.0        0.000022       948.0             0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full5 = full5.fillna(0)\n",
    "X_train_full5 = full5.iloc[:3620] \n",
    "X_test_full5 = full5.iloc[3620:] \n",
    "\n",
    "X5 = X_train_full5\n",
    "y5 = train.Result\n",
    "X5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = full.iloc[:3620].shape[0]\n",
    "ntest = full.iloc[3620:].shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 3 # set folds for out-of-fold prediction\n",
    "skf = StratifiedKFold(n_splits=NFOLDS, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf --> adalah model yang ingin digunakan\n",
    "# x_tr --> adalah tipe dataset yang ingin digunakan, seluruh data_train\n",
    "# y_tr --> adalah variabel target\n",
    "# x_test --> adalah test set untuk di lakukan prediksi, lalu di submission\n",
    "def get_oof(clf, x_tr, y_tr, x_test, deeplearning = False, deep = False):\n",
    "    count = 0\n",
    "    \n",
    "    # BUAT VECTOR UNTUK MENYIMPAN HASIL CV \n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_train_ = np.zeros((ntrain,))\n",
    "\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    oof_y_valid = np.zeros((ntrain,))\n",
    "    \n",
    "    # Cross validasi\n",
    "    for train_index, test_index in skf.split(x_tr,y_tr):\n",
    "        X_train, X_valid = x_tr.iloc[train_index], x_tr.iloc[test_index] \n",
    "        y_train, y_valid = y_tr.iloc[train_index], y_tr.iloc[test_index]\n",
    "\n",
    "        if deeplearning == True:\n",
    "            clf.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "            clf.fit(X_train,y_train,batch_size=25,epochs=10,validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "            oof_train[test_index] = clf.predict(X_valid)[:,0]\n",
    "            oof_test_skf[count,:] = clf.predict(x_test)[:,0]\n",
    "        elif deeplearning == True & deep == True:\n",
    "            clf.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "\n",
    "            clf.fit(X_train,y_train, batch_size=16, epochs=30,validation_data=(X_valid, y_valid),callbacks=[es, rlr],verbose=1)\n",
    "            oof_train[test_index] = clf.predict(X_valid)[:,0]\n",
    "            oof_test_skf[count,:] = clf.predict(x_test)[:,0]\n",
    "            \n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            oof_train[test_index] = clf.predict_proba(X_valid)[:,1]\n",
    "            oof_test_skf[count,:] = clf.predict_proba(x_test)[:,1]\n",
    "            oof_train_[test_index] = clf.predict(X_valid)\n",
    "            oof_y_valid[test_index] = y_valid\n",
    "            \n",
    "            if count > 1:\n",
    "                oof_y_pred = pd.Series(oof_train_.ravel())\n",
    "                tn, fp, fn, tp = confusion_matrix(oof_y_valid, oof_y_pred).ravel()\n",
    "                #Metric yang digunakan\n",
    "                categorization_accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "                print(categorization_accuracy)\n",
    "        count+=1\n",
    "        \n",
    "   \n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    # Output adalah matriks yg berisikan nilai prediksi\n",
    "    # oof_train --> isinya hasil prediksi dari seluruh cross validation\n",
    "    # oof_test --> isinya hasil prediksi data test (x_test)\n",
    "    # oof_y_valid --> isinya adalah seluruh target y yang asli saat di cross validation\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1), oof_y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "ext = ExtraTreesClassifier()\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0, probability=True)\n",
    "lgr = LogisticRegression()\n",
    "nb = MultinomialNB()\n",
    "xgb = XGBClassifier(n_estimators=250,scale_pos_weight =  (y.shape[0]-y.sum()) / y.sum())\n",
    "lgbm = LGBMClassifier(n_estimators = 250, scale_pos_weight=(y.shape[0]-y.sum()) / y.sum())\n",
    "\n",
    "cat = CatBoostClassifier()\n",
    "lda = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "qda = discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "dct = tree.DecisionTreeClassifier()\n",
    "nsvc =svm.NuSVC(probability=True)\n",
    "lsvc =  svm.LinearSVC()\n",
    "knc = neighbors.KNeighborsClassifier()\n",
    "ber =  naive_bayes.BernoulliNB()\n",
    "gau =  naive_bayes.GaussianNB()\n",
    "pac = linear_model.PassiveAggressiveClassifier()\n",
    "rid =   linear_model.RidgeClassifierCV()\n",
    "sgdc =  linear_model.SGDClassifier()\n",
    "per = linear_model.Perceptron()\n",
    "gaup = gaussian_process.GaussianProcessClassifier()\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "ada = ensemble.AdaBoostClassifier()\n",
    "bag = ensemble.BaggingClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost score:\n",
      "0.8325966850828729\n",
      "0.850828729281768\n",
      "0.8403314917127072\n",
      "0.8516574585635359\n",
      "0.8375690607734807\n",
      "xgbg score:\n",
      "0.8795580110497238\n",
      "0.8837016574585635\n",
      "0.8795580110497238\n",
      "0.8859116022099448\n",
      "0.8784530386740331\n",
      "lgbm score:\n",
      "0.8900552486187845\n",
      "0.8947513812154696\n",
      "0.8900552486187845\n",
      "0.9022099447513812\n",
      "0.8930939226519337\n",
      "multinomial score:\n",
      "0.8298342541436464\n",
      "0.7110497237569061\n",
      "0.6035911602209945\n",
      "0.7613259668508288\n",
      "Logistic regression score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830110497237569\n",
      "0.7110497237569061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8505524861878453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7295580110497237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8367403314917127\n",
      "svm score:\n",
      "0.7066298342541436\n",
      "0.7110497237569061\n",
      "0.7066298342541436\n",
      "0.7110497237569061\n",
      "0.7162983425414364\n",
      "extra tree:\n",
      "0.8740331491712707\n",
      "0.8767955801104972\n",
      "0.8665745856353592\n",
      "0.880939226519337\n",
      "0.8756906077348067\n",
      "lda score:\n",
      "0.7701657458563536\n",
      "0.8466850828729282\n",
      "0.8524861878453038\n",
      "0.8524861878453038\n",
      "0.7723756906077348\n",
      "qda score:\n",
      "0.7453038674033149\n",
      "0.7323204419889503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7798342541436464\n",
      "0.742817679558011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "M:\\AUDHI\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738950276243094\n",
      "decision tree score:\n",
      "0.791988950276243\n",
      "0.7980662983425414\n",
      "0.7853591160220994\n",
      "0.8024861878453039\n",
      "0.7870165745856353\n",
      "nusvc score:\n",
      "0.8074585635359116\n",
      "0.8461325966850829\n",
      "0.8110497237569061\n",
      "0.7312154696132597\n",
      "0.7834254143646409\n",
      "kneighbors score:\n",
      "0.8367403314917127\n",
      "0.8425414364640884\n",
      "0.8400552486187846\n",
      "0.7306629834254144\n",
      "0.7980662983425414\n",
      "bernouli score:\n",
      "0.6629834254143646\n",
      "0.6629834254143646\n",
      "0.6524861878453039\n",
      "0.6853591160220994\n",
      "0.6787292817679558\n",
      "gaussian score:\n",
      "0.6917127071823205\n",
      "0.7795580110497238\n",
      "0.6941988950276243\n",
      "0.7088397790055249\n",
      "0.6906077348066298\n",
      "gausian process score:\n",
      "0.8140883977900553\n",
      "0.7110497237569061\n",
      "0.819060773480663\n",
      "0.6994475138121546\n",
      "0.7787292817679557\n",
      "gradient boosting score:\n",
      "0.8629834254143647\n",
      "0.8726519337016575\n",
      "0.8616022099447513\n",
      "0.8767955801104972\n",
      "0.86353591160221\n",
      "random foreset score:\n",
      "0.875414364640884\n",
      "0.8767955801104972\n",
      "0.8767955801104972\n",
      "0.8787292817679558\n",
      "0.8743093922651933\n",
      "ada boost score:\n",
      "0.8441988950276244\n",
      "0.8569060773480663\n",
      "0.8441988950276244\n",
      "0.8585635359116022\n",
      "0.8422651933701657\n",
      "baggin score:\n",
      "0.8325966850828729\n",
      "0.8458563535911602\n",
      "0.8447513812154697\n",
      "0.855524861878453\n",
      "0.838121546961326\n"
     ]
    }
   ],
   "source": [
    "# Mengambil hasil prediksi untuk data_train, data_test per model\n",
    "\n",
    "print('catboost score:')\n",
    "xgb_oof_train191, xgb_oof_test191,oof_y_valid191 = get_oof(bag,X_train_full1, y, X_test_full1) # Bagging\n",
    "xgb_oof_train192, xgb_oof_test192,oof_y_valid192 = get_oof(bag,X_train_full2, y, X_test_full2) # Bagging\n",
    "xgb_oof_train193, xgb_oof_test193,oof_y_valid193 = get_oof(bag,X_train_full3, y, X_test_full3) # Bagging\n",
    "xgb_oof_train194, xgb_oof_test194,oof_y_valid194 = get_oof(bag,X_train_full4, y, X_test_full4) # Bagging\n",
    "xgb_oof_train195, xgb_oof_test195,oof_y_valid195 = get_oof(bag,X_train_full5, y, X_test_full5) # Bagging\n",
    "\n",
    "\n",
    "print('xgbg score:')\n",
    "xgb_oof_train11, xgb_oof_test11,oof_y_valid11 = get_oof(xgb,X_train_full1, y, X_test_full1) # Xtreme Gradient Boost\n",
    "xgb_oof_train12, xgb_oof_test12,oof_y_valid12 = get_oof(xgb,X_train_full2, y, X_test_full2) # Xtreme Gradient Boost\n",
    "xgb_oof_train13, xgb_oof_test13,oof_y_valid13 = get_oof(xgb,X_train_full3, y, X_test_full3) # Xtreme Gradient Boost\n",
    "xgb_oof_train14, xgb_oof_test14,oof_y_valid14 = get_oof(xgb,X_train_full4, y, X_test_full4) # Xtreme Gradient Boost\n",
    "xgb_oof_train15, xgb_oof_test15,oof_y_valid15 = get_oof(xgb,X_train_full5, y, X_test_full5) # Xtreme Gradient Boost\n",
    "\n",
    "print('lgbm score:')\n",
    "xgb_oof_train21, xgb_oof_test21,oof_y_valid21 = get_oof(lgbm,X_train_full1, y, X_test_full1) # LGBM\n",
    "xgb_oof_train22, xgb_oof_test22,oof_y_valid22 = get_oof(lgbm,X_train_full2, y, X_test_full2) # LGBM\n",
    "xgb_oof_train23, xgb_oof_test23,oof_y_valid23 = get_oof(lgbm,X_train_full3, y, X_test_full3) # LGBM\n",
    "xgb_oof_train24, xgb_oof_test24,oof_y_valid24 = get_oof(lgbm,X_train_full4, y, X_test_full4) # LGBM\n",
    "xgb_oof_train25, xgb_oof_test25,oof_y_valid25 = get_oof(lgbm,X_train_full5, y, X_test_full5) # LGBM\n",
    "\n",
    "print('multinomial score:')\n",
    "xgb_oof_train31, xgb_oof_test31,oof_y_valid31 = get_oof(nb,X_train_full1, y, X_test_full1) # MultinomialNB\n",
    "xgb_oof_train32, xgb_oof_test32,oof_y_valid32 = get_oof(nb,X_train_full2, y, X_test_full2) # MultinomialNB\n",
    "# xgb_oof_train33, xgb_oof_test33,oof_y_valid33 = get_oof(nb,X_train_full3, y, X_test_full3) # MultinomialNB\n",
    "xgb_oof_train34, xgb_oof_test34,oof_y_valid34 = get_oof(nb,X_train_full4, y, X_test_full4) # MultinomialNB\n",
    "xgb_oof_train35, xgb_oof_test35,oof_y_valid35 = get_oof(nb,X_train_full5, y, X_test_full5) # MultinomialNB\n",
    "\n",
    "print('Logistic regression score:')\n",
    "xgb_oof_train41, xgb_oof_test41,oof_y_valid41 = get_oof(lgr,X_train_full1, y, X_test_full1) # LogisticRegression\n",
    "xgb_oof_train42, xgb_oof_test42,oof_y_valid42 = get_oof(lgr,X_train_full2, y, X_test_full2) # LogisticRegression\n",
    "xgb_oof_train43, xgb_oof_test43,oof_y_valid43 = get_oof(lgr,X_train_full3, y, X_test_full3) # LogisticRegression\n",
    "xgb_oof_train44, xgb_oof_test44,oof_y_valid44 = get_oof(lgr,X_train_full4, y, X_test_full4) # LogisticRegression\n",
    "xgb_oof_train45, xgb_oof_test45,oof_y_valid45 = get_oof(lgr,X_train_full5, y, X_test_full5) # LogisticRegression\n",
    "\n",
    "print('svm score:')\n",
    "xgb_oof_train51, xgb_oof_test51,oof_y_valid51 = get_oof(svc,X_train_full1, y, X_test_full1) # SVM\n",
    "xgb_oof_train52, xgb_oof_test52,oof_y_valid52 = get_oof(svc,X_train_full2, y, X_test_full2) # SVM\n",
    "xgb_oof_train53, xgb_oof_test53,oof_y_valid53 = get_oof(svc,X_train_full3, y, X_test_full3) # SVM\n",
    "xgb_oof_train54, xgb_oof_test54,oof_y_valid54 = get_oof(svc,X_train_full4, y, X_test_full4) # SVM\n",
    "xgb_oof_train55, xgb_oof_test55,oof_y_valid55 = get_oof(svc,X_train_full5, y, X_test_full5) # SVM\n",
    "\n",
    "print('extra tree:')\n",
    "xgb_oof_train61, xgb_oof_test61,oof_y_valid61 = get_oof(ext,X_train_full1, y, X_test_full1) # ExtraTree\n",
    "xgb_oof_train62, xgb_oof_test62,oof_y_valid62 = get_oof(ext,X_train_full2, y, X_test_full2) # ExtraTree\n",
    "xgb_oof_train63, xgb_oof_test63,oof_y_valid63 = get_oof(ext,X_train_full3, y, X_test_full3) # ExtraTree\n",
    "xgb_oof_train64, xgb_oof_test64,oof_y_valid64 = get_oof(ext,X_train_full4, y, X_test_full4) # ExtraTree\n",
    "xgb_oof_train65, xgb_oof_test65,oof_y_valid65 = get_oof(ext,X_train_full5, y, X_test_full5) # ExtraTree\n",
    "\n",
    "print('lda score:')\n",
    "xgb_oof_train71, xgb_oof_test71,oof_y_valid71 = get_oof(lda,X_train_full1, y, X_test_full1) # LinearDiscriminantAnalysis\n",
    "xgb_oof_train72, xgb_oof_test72,oof_y_valid72 = get_oof(lda,X_train_full2, y, X_test_full2) # LinearDiscriminantAnalysis\n",
    "xgb_oof_train73, xgb_oof_test73,oof_y_valid73 = get_oof(lda,X_train_full3, y, X_test_full3) # LinearDiscriminantAnalysis\n",
    "xgb_oof_train74, xgb_oof_test74,oof_y_valid74 = get_oof(lda,X_train_full4, y, X_test_full4) # LinearDiscriminantAnalysis\n",
    "xgb_oof_train75, xgb_oof_test75,oof_y_valid75 = get_oof(lda,X_train_full5, y, X_test_full5) # LinearDiscriminantAnalysis\n",
    "\n",
    "print('qda score:')\n",
    "xgb_oof_train81, xgb_oof_test81,oof_y_valid81 = get_oof(qda,X_train_full1, y, X_test_full1) # QuadraticDiscriminantAnalysis\n",
    "xgb_oof_train82, xgb_oof_test82,oof_y_valid82 = get_oof(qda,X_train_full2, y, X_test_full2) # QuadraticDiscriminantAnalysis\n",
    "xgb_oof_train83, xgb_oof_test83,oof_y_valid83 = get_oof(qda,X_train_full3, y, X_test_full3) # QuadraticDiscriminantAnalysis\n",
    "xgb_oof_train84, xgb_oof_test84,oof_y_valid84 = get_oof(qda,X_train_full4, y, X_test_full4) # QuadraticDiscriminantAnalysis\n",
    "xgb_oof_train85, xgb_oof_test85,oof_y_valid85 = get_oof(qda,X_train_full5, y, X_test_full5) # QuadraticDiscriminantAnalysis\n",
    "\n",
    "print('decision tree score:')\n",
    "xgb_oof_train91, xgb_oof_test91,oof_y_valid91 = get_oof(dct,X_train_full1, y, X_test_full1) # DecisionTree\n",
    "xgb_oof_train92, xgb_oof_test92,oof_y_valid92 = get_oof(dct,X_train_full2, y, X_test_full2) # DecisionTree\n",
    "xgb_oof_train93, xgb_oof_test93,oof_y_valid93 = get_oof(dct,X_train_full3, y, X_test_full3) # DecisionTree\n",
    "xgb_oof_train94, xgb_oof_test94,oof_y_valid94 = get_oof(dct,X_train_full4, y, X_test_full4) # DecisionTree\n",
    "xgb_oof_train95, xgb_oof_test95,oof_y_valid95 = get_oof(dct,X_train_full5, y, X_test_full5) # DecisionTree\n",
    "\n",
    "\n",
    "print('nusvc score:')\n",
    "xgb_oof_train101, xgb_oof_test101,oof_y_valid101 = get_oof(nsvc,X_train_full1, y, X_test_full1) # NuSVC\n",
    "xgb_oof_train102, xgb_oof_test102,oof_y_valid102 = get_oof(nsvc,X_train_full2, y, X_test_full2) # NuSVC\n",
    "xgb_oof_train103, xgb_oof_test103,oof_y_valid103 = get_oof(nsvc,X_train_full3, y, X_test_full3) # NuSVC\n",
    "xgb_oof_train104, xgb_oof_test104,oof_y_valid104 = get_oof(nsvc,X_train_full4, y, X_test_full4) # NuSVC\n",
    "xgb_oof_train105, xgb_oof_test105,oof_y_valid105 = get_oof(nsvc,X_train_full5, y, X_test_full5) # NuSVC\n",
    "\n",
    "print('kneighbors score:')\n",
    "xgb_oof_train111, xgb_oof_test111,oof_y_valid111 = get_oof(knc,X_train_full1, y, X_test_full1) # KNeighborsClassifier\n",
    "xgb_oof_train112, xgb_oof_test112,oof_y_valid112 = get_oof(knc,X_train_full2, y, X_test_full2) # KNeighborsClassifier\n",
    "xgb_oof_train113, xgb_oof_test113,oof_y_valid113 = get_oof(knc,X_train_full3, y, X_test_full3) # KNeighborsClassifier\n",
    "xgb_oof_train114, xgb_oof_test114,oof_y_valid114 = get_oof(knc,X_train_full4, y, X_test_full4) # KNeighborsClassifier\n",
    "xgb_oof_train115, xgb_oof_test115,oof_y_valid115 = get_oof(knc,X_train_full5, y, X_test_full5) # KNeighborsClassifier\n",
    "\n",
    "print('bernouli score:')\n",
    "xgb_oof_train121, xgb_oof_test121,oof_y_valid121 = get_oof(ber,X_train_full1, y, X_test_full1) # BernoulliNB\n",
    "xgb_oof_train122, xgb_oof_test122,oof_y_valid122 = get_oof(ber,X_train_full2, y, X_test_full2) # BernoulliNB\n",
    "xgb_oof_train123, xgb_oof_test123,oof_y_valid123 = get_oof(ber,X_train_full3, y, X_test_full3) # BernoulliNB\n",
    "xgb_oof_train124, xgb_oof_test124,oof_y_valid124 = get_oof(ber,X_train_full4, y, X_test_full4) # BernoulliNB\n",
    "xgb_oof_train125, xgb_oof_test125,oof_y_valid125 = get_oof(ber,X_train_full5, y, X_test_full5) # BernoulliNB\n",
    "\n",
    "print('gaussian score:')\n",
    "xgb_oof_train131, xgb_oof_test131,oof_y_valid131 = get_oof(gau,X_train_full1, y, X_test_full1) # GaussianNB\n",
    "xgb_oof_train132, xgb_oof_test132,oof_y_valid132 = get_oof(gau,X_train_full2, y, X_test_full2) # GaussianNB\n",
    "xgb_oof_train133, xgb_oof_test133,oof_y_valid133 = get_oof(gau,X_train_full3, y, X_test_full3) # GaussianNB\n",
    "xgb_oof_train134, xgb_oof_test134,oof_y_valid134 = get_oof(gau,X_train_full4, y, X_test_full4) # GaussianNB\n",
    "xgb_oof_train135, xgb_oof_test135,oof_y_valid135 = get_oof(gau,X_train_full5, y, X_test_full5) # GaussianNB\n",
    "\n",
    "print('gausian process score:')\n",
    "xgb_oof_train141, xgb_oof_test141,oof_y_valid141 = get_oof(gaup,X_train_full1, y, X_test_full1) # GaussianProcess\n",
    "xgb_oof_train142, xgb_oof_test142,oof_y_valid142 = get_oof(gaup,X_train_full2, y, X_test_full2) # GaussianProcess\n",
    "xgb_oof_train143, xgb_oof_test143,oof_y_valid143 = get_oof(gaup,X_train_full3, y, X_test_full3) # GaussianProcess\n",
    "xgb_oof_train144, xgb_oof_test144,oof_y_valid144 = get_oof(gaup,X_train_full4, y, X_test_full4) # GaussianProcess\n",
    "xgb_oof_train145, xgb_oof_test145,oof_y_valid145 = get_oof(gaup,X_train_full5, y, X_test_full5) # GaussianProcess\n",
    "\n",
    "print('gradient boosting score:')\n",
    "xgb_oof_train151, xgb_oof_test151,oof_y_valid151 = get_oof(gbc,X_train_full1, y, X_test_full1) # GradientBoosting\n",
    "xgb_oof_train152, xgb_oof_test152,oof_y_valid152 = get_oof(gbc,X_train_full2, y, X_test_full2) # GradientBoosting\n",
    "xgb_oof_train153, xgb_oof_test153,oof_y_valid153 = get_oof(gbc,X_train_full3, y, X_test_full3) # GradientBoosting\n",
    "xgb_oof_train154, xgb_oof_test154,oof_y_valid154 = get_oof(gbc,X_train_full4, y, X_test_full4) # GradientBoosting\n",
    "xgb_oof_train155, xgb_oof_test155,oof_y_valid155 = get_oof(gbc,X_train_full5, y, X_test_full5) # GradientBoosting\n",
    "\n",
    "print('random foreset score:')\n",
    "xgb_oof_train161, xgb_oof_test161,oof_y_valid161 = get_oof(rf,X_train_full1, y, X_test_full1) # RandomForest\n",
    "xgb_oof_train162, xgb_oof_test162,oof_y_valid162 = get_oof(rf,X_train_full2, y, X_test_full2) # RandomForest\n",
    "xgb_oof_train163, xgb_oof_test163,oof_y_valid163 = get_oof(rf,X_train_full3, y, X_test_full3) # RandomForest\n",
    "xgb_oof_train164, xgb_oof_test164,oof_y_valid164 = get_oof(rf,X_train_full4, y, X_test_full4) # RandomForest\n",
    "xgb_oof_train165, xgb_oof_test165,oof_y_valid165 = get_oof(rf,X_train_full5, y, X_test_full5) # RandomForest\n",
    "\n",
    "print('ada boost score:')\n",
    "xgb_oof_train171, xgb_oof_test171,oof_y_valid171 = get_oof(ada,X_train_full1, y, X_test_full1) # AdaBoost\n",
    "xgb_oof_train172, xgb_oof_test172,oof_y_valid172 = get_oof(ada,X_train_full2, y, X_test_full2) # AdaBoost\n",
    "xgb_oof_train173, xgb_oof_test173,oof_y_valid173 = get_oof(ada,X_train_full3, y, X_test_full3) # AdaBoost\n",
    "xgb_oof_train174, xgb_oof_test174,oof_y_valid174 = get_oof(ada,X_train_full4, y, X_test_full4) # AdaBoost\n",
    "xgb_oof_train175, xgb_oof_test175,oof_y_valid175 = get_oof(ada,X_train_full5, y, X_test_full5) # AdaBoost\n",
    "\n",
    "print('baggin score:')\n",
    "xgb_oof_train181, xgb_oof_test181,oof_y_valid181 = get_oof(bag,X_train_full1, y, X_test_full1) # Bagging\n",
    "xgb_oof_train182, xgb_oof_test182,oof_y_valid182 = get_oof(bag,X_train_full2, y, X_test_full2) # Bagging\n",
    "xgb_oof_train183, xgb_oof_test183,oof_y_valid183 = get_oof(bag,X_train_full3, y, X_test_full3) # Bagging\n",
    "xgb_oof_train184, xgb_oof_test184,oof_y_valid184 = get_oof(bag,X_train_full4, y, X_test_full4) # Bagging\n",
    "xgb_oof_train185, xgb_oof_test185,oof_y_valid185 = get_oof(bag,X_train_full5, y, X_test_full5) # Bagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model11</th>\n",
       "      <th>Model12</th>\n",
       "      <th>Model13</th>\n",
       "      <th>Model14</th>\n",
       "      <th>Model15</th>\n",
       "      <th>Model21</th>\n",
       "      <th>Model22</th>\n",
       "      <th>Model23</th>\n",
       "      <th>Model24</th>\n",
       "      <th>Model25</th>\n",
       "      <th>...</th>\n",
       "      <th>Model181</th>\n",
       "      <th>Model182</th>\n",
       "      <th>Model183</th>\n",
       "      <th>Model184</th>\n",
       "      <th>Model185</th>\n",
       "      <th>Model191</th>\n",
       "      <th>Model192</th>\n",
       "      <th>Model193</th>\n",
       "      <th>Model194</th>\n",
       "      <th>Model195</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087550</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.087550</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.081417</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>2.394428e-06</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>0.013996</td>\n",
       "      <td>0.282099</td>\n",
       "      <td>0.060281</td>\n",
       "      <td>5.067280e-04</td>\n",
       "      <td>0.060281</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.215628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065451</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.065451</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.030174</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>1.835899e-05</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047933</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.047933</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.051857</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>7.450735e-07</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.954240</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.872586</td>\n",
       "      <td>0.900522</td>\n",
       "      <td>0.900233</td>\n",
       "      <td>8.720060e-01</td>\n",
       "      <td>0.900233</td>\n",
       "      <td>0.915125</td>\n",
       "      <td>0.966265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model11   Model12   Model13   Model14   Model15   Model21       Model22  \\\n",
       "0  0.087550  0.002989  0.087550  0.006839  0.081417  0.001195  2.394428e-06   \n",
       "1  0.225586  0.022197  0.225586  0.013996  0.282099  0.060281  5.067280e-04   \n",
       "2  0.065451  0.003842  0.065451  0.008908  0.030174  0.002135  1.835899e-05   \n",
       "3  0.047933  0.004834  0.047933  0.007380  0.051857  0.000047  7.450735e-07   \n",
       "4  0.930889  0.954240  0.930889  0.872586  0.900522  0.900233  8.720060e-01   \n",
       "\n",
       "    Model23   Model24   Model25  ...  Model181  Model182  Model183  Model184  \\\n",
       "0  0.001195  0.000003  0.000528  ...       0.0       0.0       0.0       0.0   \n",
       "1  0.060281  0.000127  0.215628  ...       0.6       0.1       0.4       0.0   \n",
       "2  0.002135  0.000014  0.000127  ...       0.1       0.0       0.2       0.0   \n",
       "3  0.000047  0.000006  0.000114  ...       0.0       0.0       0.0       0.0   \n",
       "4  0.900233  0.915125  0.966265  ...       0.4       0.6       0.6       0.7   \n",
       "\n",
       "   Model185  Model191  Model192  Model193  Model194  Model195  \n",
       "0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "1       0.5       0.6       0.0       0.6       0.1       0.1  \n",
       "2       0.1       0.0       0.0       0.1       0.1       0.0  \n",
       "3       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4       0.5       0.2       0.7       0.3       0.9       0.4  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Membuat dataframe dari seluruh hasil prediksi data train\n",
    "base_predictions_train = pd.DataFrame( {\n",
    "\n",
    "    'Model11': xgb_oof_train11.ravel(),\n",
    "    'Model12': xgb_oof_train12.ravel(),\n",
    "    'Model13': xgb_oof_train13.ravel(),\n",
    "    'Model14': xgb_oof_train14.ravel(),\n",
    "    'Model15': xgb_oof_train15.ravel(),\n",
    "\n",
    "    'Model21': xgb_oof_train21.ravel(),\n",
    "    'Model22': xgb_oof_train22.ravel(),\n",
    "    'Model23': xgb_oof_train23.ravel(),\n",
    "    'Model24': xgb_oof_train24.ravel(),\n",
    "    'Model25': xgb_oof_train25.ravel(),\n",
    "    \n",
    "    'Model31': xgb_oof_train31.ravel(),\n",
    "    'Model32': xgb_oof_train32.ravel(),\n",
    "#     'Model33': xgb_oof_train33.ravel(),\n",
    "    'Model34': xgb_oof_train34.ravel(),\n",
    "    'Model35': xgb_oof_train35.ravel(),\n",
    "    \n",
    "    'Model41': xgb_oof_train41.ravel(),\n",
    "    'Model42': xgb_oof_train42.ravel(),\n",
    "    'Model43': xgb_oof_train43.ravel(),\n",
    "    'Model44': xgb_oof_train44.ravel(),\n",
    "    'Model45': xgb_oof_train45.ravel(),\n",
    "    \n",
    "    \n",
    "    'Model51': xgb_oof_train51.ravel(),\n",
    "    'Model52': xgb_oof_train52.ravel(),\n",
    "    'Model53': xgb_oof_train53.ravel(),\n",
    "    'Model54': xgb_oof_train54.ravel(),\n",
    "    'Model55': xgb_oof_train55.ravel(),\n",
    "    \n",
    "    'Model61': xgb_oof_train61.ravel(),\n",
    "    'Model62': xgb_oof_train62.ravel(),\n",
    "    'Model63': xgb_oof_train63.ravel(),\n",
    "    'Model64': xgb_oof_train64.ravel(),\n",
    "    'Model65': xgb_oof_train65.ravel(),\n",
    "    \n",
    "    \n",
    "    'Model71': xgb_oof_train71.ravel(),\n",
    "    'Model72': xgb_oof_train72.ravel(),\n",
    "    'Model73': xgb_oof_train73.ravel(),\n",
    "    'Model74': xgb_oof_train74.ravel(),\n",
    "    'Model75': xgb_oof_train75.ravel(),\n",
    "   \n",
    "    'Model81': xgb_oof_train81.ravel(),\n",
    "    'Model82': xgb_oof_train82.ravel(),\n",
    "    'Model83': xgb_oof_train83.ravel(),\n",
    "    'Model84': xgb_oof_train84.ravel(),\n",
    "    'Model85': xgb_oof_train85.ravel(),\n",
    "    \n",
    "    'Model91': xgb_oof_train91.ravel(),\n",
    "    'Model92': xgb_oof_train92.ravel(),\n",
    "    'Model93': xgb_oof_train93.ravel(),\n",
    "    'Model94': xgb_oof_train94.ravel(),\n",
    "    'Model95': xgb_oof_train95.ravel(),\n",
    "    \n",
    "    'Model101': xgb_oof_train101.ravel(),\n",
    "    'Model102': xgb_oof_train102.ravel(),\n",
    "    'Model103': xgb_oof_train103.ravel(),\n",
    "    'Model104': xgb_oof_train104.ravel(),\n",
    "    'Model105': xgb_oof_train105.ravel(),\n",
    "    \n",
    "    \n",
    "    'Model111': xgb_oof_train111.ravel(),\n",
    "    'Model112': xgb_oof_train112.ravel(),\n",
    "    'Model113': xgb_oof_train113.ravel(),\n",
    "    'Model114': xgb_oof_train114.ravel(),\n",
    "    'Model115': xgb_oof_train115.ravel(),\n",
    "    \n",
    "    'Model121': xgb_oof_train121.ravel(),\n",
    "    'Model122': xgb_oof_train122.ravel(),\n",
    "    'Model123': xgb_oof_train123.ravel(),\n",
    "    'Model124': xgb_oof_train124.ravel(),\n",
    "    'Model125': xgb_oof_train125.ravel(),\n",
    "    \n",
    "    \n",
    "    'Model131': xgb_oof_train131.ravel(),\n",
    "    'Model132': xgb_oof_train132.ravel(),\n",
    "    'Model133': xgb_oof_train133.ravel(),\n",
    "    'Model134': xgb_oof_train134.ravel(),\n",
    "    'Model135': xgb_oof_train135.ravel(),\n",
    "    \n",
    "    \n",
    "    'Model141': xgb_oof_train141.ravel(),\n",
    "    'Model142': xgb_oof_train142.ravel(),\n",
    "    'Model143': xgb_oof_train143.ravel(),\n",
    "    'Model144': xgb_oof_train144.ravel(),\n",
    "    'Model145': xgb_oof_train145.ravel(),\n",
    "    \n",
    "    'Model151': xgb_oof_train151.ravel(),\n",
    "    'Model152': xgb_oof_train152.ravel(),\n",
    "    'Model153': xgb_oof_train153.ravel(),\n",
    "    'Model154': xgb_oof_train154.ravel(),\n",
    "    'Model155': xgb_oof_train155.ravel(),\n",
    "    \n",
    "    'Model161': xgb_oof_train161.ravel(),\n",
    "    'Model162': xgb_oof_train162.ravel(),\n",
    "    'Model163': xgb_oof_train163.ravel(),\n",
    "    'Model164': xgb_oof_train164.ravel(),\n",
    "    'Model165': xgb_oof_train165.ravel(),\n",
    "    \n",
    "    'Model171': xgb_oof_train171.ravel(),\n",
    "    'Model172': xgb_oof_train172.ravel(),\n",
    "    'Model173': xgb_oof_train173.ravel(),\n",
    "    'Model174': xgb_oof_train174.ravel(),\n",
    "    'Model175': xgb_oof_train175.ravel(),\n",
    "    \n",
    "    'Model181': xgb_oof_train181.ravel(),\n",
    "    'Model182': xgb_oof_train182.ravel(),\n",
    "    'Model183': xgb_oof_train183.ravel(),\n",
    "    'Model184': xgb_oof_train184.ravel(),\n",
    "    'Model185': xgb_oof_train185.ravel(),\n",
    "    \n",
    "    'Model191': xgb_oof_train191.ravel(),\n",
    "    'Model192': xgb_oof_train192.ravel(),\n",
    "    'Model193': xgb_oof_train193.ravel(),\n",
    "    'Model194': xgb_oof_train194.ravel(),\n",
    "    'Model195': xgb_oof_train195.ravel(),\n",
    "    })\n",
    "base_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat kolom hasil prediksi dari data_train (seluruh model)\n",
    "x_train = np.concatenate((  \n",
    "    xgb_oof_train11,\n",
    "    xgb_oof_train12,\n",
    "    xgb_oof_train13,\n",
    "    xgb_oof_train14,\n",
    "    xgb_oof_train15,\n",
    "\n",
    "    xgb_oof_train21,\n",
    "    xgb_oof_train22,\n",
    "    xgb_oof_train23,\n",
    "    xgb_oof_train24,\n",
    "    xgb_oof_train25,\n",
    "    \n",
    "    xgb_oof_train31,\n",
    "    xgb_oof_train32,\n",
    "    xgb_oof_train34,\n",
    "    xgb_oof_train35,\n",
    "    \n",
    "    xgb_oof_train41,\n",
    "    xgb_oof_train42,\n",
    "    xgb_oof_train43,\n",
    "    xgb_oof_train44,\n",
    "    xgb_oof_train45,\n",
    "    \n",
    "    \n",
    "    xgb_oof_train51,\n",
    "    xgb_oof_train52,\n",
    "    xgb_oof_train53,\n",
    "    xgb_oof_train54,\n",
    "    xgb_oof_train55,\n",
    "    \n",
    "    xgb_oof_train61,\n",
    "    xgb_oof_train62,\n",
    "    xgb_oof_train63,\n",
    "    xgb_oof_train64,\n",
    "    xgb_oof_train65,\n",
    "    \n",
    "    \n",
    "    xgb_oof_train71,\n",
    "    xgb_oof_train72,\n",
    "    xgb_oof_train73,\n",
    "    xgb_oof_train74,\n",
    "    xgb_oof_train75,\n",
    "   \n",
    "    xgb_oof_train81,\n",
    "    xgb_oof_train82,\n",
    "    xgb_oof_train83,\n",
    "    xgb_oof_train84,\n",
    "    xgb_oof_train85,\n",
    "    \n",
    "    xgb_oof_train91,\n",
    "    xgb_oof_train92,\n",
    "    xgb_oof_train93,\n",
    "    xgb_oof_train94,\n",
    "    xgb_oof_train95,\n",
    "    \n",
    "    xgb_oof_train101,\n",
    "    xgb_oof_train102,\n",
    "    xgb_oof_train103,\n",
    "    xgb_oof_train104,\n",
    "    xgb_oof_train105,\n",
    "    \n",
    "    \n",
    "    xgb_oof_train111,\n",
    "    xgb_oof_train112,\n",
    "    xgb_oof_train113,\n",
    "    xgb_oof_train114,\n",
    "    xgb_oof_train115,\n",
    "    \n",
    "    xgb_oof_train121,\n",
    "    xgb_oof_train122,\n",
    "    xgb_oof_train123,\n",
    "    xgb_oof_train124,\n",
    "    xgb_oof_train125,\n",
    "    \n",
    "    \n",
    "    xgb_oof_train131,\n",
    "    xgb_oof_train132,\n",
    "    xgb_oof_train133,\n",
    "    xgb_oof_train134,\n",
    "    xgb_oof_train135,\n",
    "    \n",
    "    \n",
    "    xgb_oof_train141,\n",
    "    xgb_oof_train142,\n",
    "    xgb_oof_train143,\n",
    "    xgb_oof_train144,\n",
    "    xgb_oof_train145,\n",
    "    \n",
    "    xgb_oof_train151,\n",
    "    xgb_oof_train152,\n",
    "    xgb_oof_train153,\n",
    "    xgb_oof_train154,\n",
    "    xgb_oof_train155,\n",
    "    \n",
    "    xgb_oof_train161,\n",
    "    xgb_oof_train162,\n",
    "    xgb_oof_train163,\n",
    "    xgb_oof_train164,\n",
    "    xgb_oof_train165,\n",
    "    \n",
    "    xgb_oof_train171,\n",
    "    xgb_oof_train172,\n",
    "    xgb_oof_train173,\n",
    "    xgb_oof_train174,\n",
    "    xgb_oof_train175,\n",
    "    \n",
    "    xgb_oof_train181,\n",
    "    xgb_oof_train182,\n",
    "    xgb_oof_train183,\n",
    "    xgb_oof_train184,\n",
    "    xgb_oof_train185,\n",
    "    \n",
    "    xgb_oof_train191,\n",
    "    xgb_oof_train192,\n",
    "    xgb_oof_train193,\n",
    "    xgb_oof_train194,\n",
    "    xgb_oof_train195), axis=1)\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat kolom hasil prediksi dari data_Test (seluruh model)\n",
    "x_test = np.concatenate((xgb_oof_test11,\n",
    "    xgb_oof_test12,\n",
    "    xgb_oof_test13,\n",
    "    xgb_oof_test14,\n",
    "    xgb_oof_test15,\n",
    "\n",
    "    xgb_oof_test21,\n",
    "    xgb_oof_test22,\n",
    "    xgb_oof_test23,\n",
    "    xgb_oof_test24,\n",
    "    xgb_oof_test25,\n",
    "    \n",
    "    xgb_oof_test31,\n",
    "    xgb_oof_test32,\n",
    "\n",
    "    xgb_oof_test34,\n",
    "    xgb_oof_test35,\n",
    "    \n",
    "    xgb_oof_test41,\n",
    "    xgb_oof_test42,\n",
    "    xgb_oof_test43,\n",
    "    xgb_oof_test44,\n",
    "    xgb_oof_test45,\n",
    "    \n",
    "    \n",
    "    xgb_oof_test51,\n",
    "    xgb_oof_test52,\n",
    "    xgb_oof_test53,\n",
    "    xgb_oof_test54,\n",
    "    xgb_oof_test55,\n",
    "    \n",
    "    xgb_oof_test61,\n",
    "    xgb_oof_test62,\n",
    "    xgb_oof_test63,\n",
    "    xgb_oof_test64,\n",
    "    xgb_oof_test65,\n",
    "    \n",
    "    \n",
    "    xgb_oof_test71,\n",
    "    xgb_oof_test72,\n",
    "    xgb_oof_test73,\n",
    "    xgb_oof_test74,\n",
    "    xgb_oof_test75,\n",
    "   \n",
    "    xgb_oof_test81,\n",
    "    xgb_oof_test82,\n",
    "    xgb_oof_test83,\n",
    "    xgb_oof_test84,\n",
    "    xgb_oof_test85,\n",
    "    \n",
    "    xgb_oof_test91,\n",
    "    xgb_oof_test92,\n",
    "    xgb_oof_test93,\n",
    "    xgb_oof_test94,\n",
    "    xgb_oof_test95,\n",
    "    \n",
    "    xgb_oof_test101,\n",
    "    xgb_oof_test102,\n",
    "    xgb_oof_test103,\n",
    "    xgb_oof_test104,\n",
    "    xgb_oof_test105,\n",
    "    \n",
    "    \n",
    "    xgb_oof_test111,\n",
    "    xgb_oof_test112,\n",
    "    xgb_oof_test113,\n",
    "    xgb_oof_test114,\n",
    "    xgb_oof_test115,\n",
    "    \n",
    "    xgb_oof_test121,\n",
    "    xgb_oof_test122,\n",
    "    xgb_oof_test123,\n",
    "    xgb_oof_test124,\n",
    "    xgb_oof_test125,\n",
    "    \n",
    "    \n",
    "    xgb_oof_test131,\n",
    "    xgb_oof_test132,\n",
    "    xgb_oof_test133,\n",
    "    xgb_oof_test134,\n",
    "    xgb_oof_test135,\n",
    "    \n",
    "    \n",
    "    xgb_oof_test141,\n",
    "    xgb_oof_test142,\n",
    "    xgb_oof_test143,\n",
    "    xgb_oof_test144,\n",
    "    xgb_oof_test145,\n",
    "    \n",
    "    xgb_oof_test151,\n",
    "    xgb_oof_test152,\n",
    "    xgb_oof_test153,\n",
    "    xgb_oof_test154,\n",
    "    xgb_oof_test155,\n",
    "    \n",
    "    xgb_oof_test161,\n",
    "    xgb_oof_test162,\n",
    "    xgb_oof_test163,\n",
    "    xgb_oof_test164,\n",
    "    xgb_oof_test165,\n",
    "    \n",
    "    xgb_oof_test171,\n",
    "    xgb_oof_test172,\n",
    "    xgb_oof_test173,\n",
    "    xgb_oof_test174,\n",
    "    xgb_oof_test175,\n",
    "    \n",
    "    xgb_oof_test181,\n",
    "    xgb_oof_test182,\n",
    "    xgb_oof_test183,\n",
    "    xgb_oof_test184,\n",
    "    xgb_oof_test185,\n",
    "    \n",
    "    xgb_oof_test191,\n",
    "    xgb_oof_test192,\n",
    "    xgb_oof_test193,\n",
    "    xgb_oof_test194,\n",
    "    xgb_oof_test195,\n",
    "    ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_model, model ini digunakan untuk training data hasil prediksi kita --> x_train\n",
    "gbm = XGBClassifier( n_estimators= 250,max_depth= 4,min_child_weight= 2,gamma=0.9, subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',\n",
    "                    nthread= -1,scale_pos_weight =  (y.shape[0]-y.sum()) / y.sum()) # default parameter :learning_rate = 0.02,#gamma=1,\n",
    "gbm.fit(x_train, y)\n",
    "\n",
    "# lalu hasil model tersebut dilakukan prediksi ke x_test\n",
    "predictions2 = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lakukan training stacking dari awal sebanyak 3x, lalu voting 3 hasil prediksi dengan mengambil nilai mode per baris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Result\n",
       "0  3621       0\n",
       "1  3622       0\n",
       "2  3623       0\n",
       "3  3624       0\n",
       "4  3625       0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_stacking1= pd.DataFrame(test.iloc[:,0])\n",
    "submit_stacking1['Result'] = predictions2\n",
    "submit_stacking1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1077\n",
       "1     475\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_stacking1.Result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Result\n",
       "0  3621       0\n",
       "1  3622       0\n",
       "2  3623       0\n",
       "3  3624       0\n",
       "4  3625       0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_stacking2= pd.DataFrame(test.iloc[:,0])\n",
    "submit_stacking2['Result'] = predictions2\n",
    "submit_stacking2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1077\n",
       "1     475\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_stacking2.Result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Result\n",
       "0  3621       0\n",
       "1  3622       0\n",
       "2  3623       0\n",
       "3  3624       0\n",
       "4  3625       0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_stacking3= pd.DataFrame(test.iloc[:,0])\n",
    "submit_stacking3['Result'] = predictions2\n",
    "submit_stacking3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1077\n",
       "1     475\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_stacking3.Result.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame()\n",
    "fi['R1'] = submit_stacking1.Result\n",
    "fi['R2'] = submit_stacking2.Result\n",
    "fi['R3'] = submit_stacking3.Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bin = list()\n",
    "from statistics import mode\n",
    "for i in range(len(fi)):\n",
    "    final_bin.append(mode(fi.iloc[i,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hasil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-96c855a3bea9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msubmit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msubmit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Result'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhasil\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'final'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hasil' is not defined"
     ]
    }
   ],
   "source": [
    "submit = pd.DataFrame(test.iloc[:,0])\n",
    "submit['Result'] = hasil['final']\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.Result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "submit.to_csv('final_ensemble_bin.csv', index=False)\n",
    "\n",
    "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create a link to download the dataframe which was saved with .to_csv method\n",
    "create_download_link(filename='final_ensemble_bin.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
